extern "C" {
    //fn sinf(f32) -> f32;
    //fn cosf(f32) -> f32;
    fn tanf(f32) -> f32;
    fn asinf(f32) -> f32;
    fn acosf(f32) -> f32;
    fn atanf(f32) -> f32;
    fn erff(f32) -> f32;
    fn fmodf(f32, f32) -> f32;
    fn atan2f(f32, f32) -> f32;
    fn "anydsl_isinff"    isinff(f32) -> i32;
    fn "anydsl_isnanf"    isnanf(f32) -> i32;
    fn "anydsl_isfinitef" isfinitef(f32) -> i32;
    //fn sin(f64) -> f64;
    //fn cos(f64) -> f64;
    fn tan(f64) -> f64;
    fn asin(f64) -> f64;
    fn acos(f64) -> f64;
    fn atan(f64) -> f64;
    fn erf(f64) -> f64;
    fn fmod(f64, f64) -> f64;
    fn atan2(f64, f64) -> f64;
    fn "anydsl_isinf"     isinf(f64) -> i32;
    fn "anydsl_isnan"     isnan(f64) -> i32;
    fn "anydsl_isfinite"  isfinite(f64) -> i32;
}

// kind: Xchg Add Sub And Nand Or Xor Max Min
fn atomic_xchg(a: &mut i32, b: i32) -> i32 { atomic(0u, a, b) }
fn atomic_add(a: &mut i32, b: i32) -> i32 { atomic(1u, a, b) }
fn atomic_sub(a: &mut i32, b: i32) -> i32 { atomic(2u, a, b) }
fn atomic_max(a: &mut i32, b: i32) -> i32 { atomic(7u, a, b) }
fn atomic_min(a: &mut i32, b: i32) -> i32 { atomic(8u, a, b) }

extern "device" {
    fn "llvm.exp.f32"      expf(f32) -> f32;
    fn "llvm.exp2.f32"     exp2f(f32) -> f32;
    fn "llvm.log.f32"      logf(f32) -> f32;
    fn "llvm.log2.f32"     log2f(f32) -> f32;
    fn "llvm.pow.f32"      powf(f32, f32) -> f32;
    fn "llvm.sqrt.f32"     sqrtf(f32) -> f32;
    fn "llvm.fabs.f32"     fabsf(f32) -> f32;
    fn "llvm.sin.f32"      sinf(f32) -> f32;
    fn "llvm.cos.f32"      cosf(f32) -> f32;
    fn "llvm.floor.f32"    floorf(f32) -> f32;
    fn "llvm.fma.f32"      fmaf(f32, f32, f32) -> f32;
    fn "llvm.fmuladd.f32"  madf(f32, f32, f32) -> f32;
    fn "llvm.exp.f64"      exp(f64) -> f64;
    fn "llvm.pow.f64"      pow(f64) -> f64;
    fn "llvm.sqrt.f64"     sqrt(f64) -> f64;
    fn "llvm.fabs.f64"     fabs(f64) -> f64;
    fn "llvm.sin.f64"      sin(f64) -> f64;
    fn "llvm.cos.f64"      cos(f64) -> f64;
    fn "llvm.floor.f64"    floor(f64) -> f64;
    fn "llvm.fma.f64"      fma(f64, f64, f64) -> f64;
    fn "llvm.fmuladd.f64"  mad(f64, f64, f64) -> f64;
    fn "llvm.copysign.f32" copysignf(f32, f32) -> f32;
    fn "llvm.copysign.f64" copysign(f64, f64) -> f64;
}

fn rsqrtf(a: f32) -> f32 { 1.0f / sqrtf(a) }
fn rsqrt(a: f64) -> f64 { 1.0 / sqrt(a) }

fn fminf(a: f32, b: f32) -> f32 { if a < b { a } else { b } }
fn fmaxf(a: f32, b: f32) -> f32 { if a > b { a } else { b } }
fn fmin(a: f64, b: f64) -> f64 { if a < b { a } else { b } }
fn fmax(a: f64, b: f64) -> f64 { if a > b { a } else { b } }

extern "device" {
    fn "llvm.x86.sse.movmsk.ps" movmskps128(simd[f32 * 4]) -> i32;
    fn "llvm.x86.sse.cmp.ps" cmpps128(simd[f32 * 4], simd[f32 * 4], i8) -> simd[f32 * 4];
    fn "llvm.x86.sse.rcp.ps" rcpps128(simd[f32 * 4]) -> simd[f32 * 4];
    fn "llvm.x86.sse.rsqrt.ps" rsqrtps128(simd[f32 * 4]) -> simd[f32 * 4];
    fn "llvm.x86.sse41.blendvps" blendvps128(simd[f32 * 4], simd[f32 * 4], simd[f32 * 4]) -> simd[f32 * 4];

    fn "llvm.x86.avx.movmsk.ps.256" movmskps256(simd[f32 * 8]) -> i32;
    fn "llvm.x86.avx.cmp.ps.256" cmpps256(simd[f32 * 8], simd[f32 * 8], i8) -> simd[f32 * 8];
    fn "llvm.x86.avx.rcp.ps.256" rcpps256(simd[f32 * 8]) -> simd[f32 * 8];
    fn "llvm.x86.avx.rsqrt.ps.256" rsqrtps256(simd[f32 * 8]) -> simd[f32 * 8];
    fn "llvm.x86.avx.blendv.ps.256" blendvps256(simd[f32 * 8], simd[f32 * 8], simd[f32 * 8]) -> simd[f32 * 8];
}

fn ldg_f32(a: &f32) -> f32 { *a }
fn ldg_i32(a: &i32) -> i32 { *a }

fn bitcast_mem_f32(ptr: &[i8]) -> &[f32] { bitcast[&[f32]](ptr) }
fn bitcast_mem_i16(ptr: &[i8]) -> &[i16] { bitcast[&[i16]](ptr) }
fn bitcast_mem_mutf32(ptr: &[i8]) -> &mut[f32] { bitcast[&mut[f32]](ptr) }
fn bitcast_mem_muti16(ptr: &[i8]) -> &mut[i16] { bitcast[&mut[i16]](ptr) }

fn get_vector_length() -> int { 8 }
fn get_alignment() -> int { 32 }
fn get_thread_count() -> int { 4 }

fn outer_loop(lower: int, upper: int, body: fn(int) -> ()) -> () {
    for i in parallel(@get_thread_count(), lower, upper) {
        body(i);
    }
}
fn outer_loop_step(lower: int, upper: int, step: int, body: fn(int) -> ()) -> () {
    for i in parallel(@get_thread_count(), 0, (upper-lower)/step) {
        body(i * step + lower);
    }
}
fn inner_loop(lower: int, upper: int, body: fn(int) -> ()) -> () {
    // TODO: make sure lower and upper are a multiple of vector length
    for i in vectorize(@get_vector_length(), @get_alignment(), lower, upper) {
        body(i);
    }
}
fn inner_loop_step(lower: int, upper: int, step: int, body: fn(int) -> ()) -> () {
    // TODO: make sure lower and upper are a multiple of vector length
    for i in vectorize(@get_vector_length(), @get_alignment(), 0, (upper-lower)/step) {
        body(i * step + lower);
    }
}
